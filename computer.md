# 计算机基础

## 操作系统

### 进程

* 进程同步互斥的机制有两种： 信号量机制  管程  

  > 管程是一个含有数据结构和操作过程的模块 类似于进程  不同的是管程师被动的 进程是主动的 对于资源的pc操作方法都是管程内部的 但是信号量机制不是这样的 他的操作都是进程的方法

* 原子操作： 指的是执行某一个功能的一定的过程 他的特点是要么不执行要么执行完毕 不能中途中断 典型的对信号量访问的原子操作： wait signal

#### 经典的进程同步问题 

1. 生产者消费者问题：有个公共缓冲池 其中有n个缓冲区 生产者和消费者不可同时同时操作  生产者生产完毕放入缓冲池 消费者取走缓冲池中的资源 缓冲池满的时候不允许放入  为空时不允许取
2. 哲学家进餐问题 五个哲学家 五个筷子 哲学家饥饿时可以拿起左右的筷子进餐  最多只允许四个哲学家同时试图拿起筷子 
3. 读者写者问题 可以允许多个读者同时访问资源 不允许读者写者同时访问  

#### 进程的通信类型

1. 共享存储器系统  利用共享某些数据结构或者共享存储区 通过这写空间进行通信 

   > 共享数据结构是低级通信 比如使用有届缓冲区这种数据结构 需要程序员自己维护
   >
   > 共享存储区 操作系统提供一块通信的共享存储区 通信进程申请读写存储区 高级通信

2. 消息传递系统  直接利用操作系统提供的一对send和receive原语操作按照格式化的消息直接通信 可以传递大量数据 高级通信 应用最广泛

3. 管道通信 读写进程通过一个共享文件 称为pipe文件链接起来 发送进程通过字符流的形式将信息写入共享文件 管道机制需要提供互斥和同步能力 发送进程发送一定的数据量写入共享文件后 便去睡眠等待 接受进程唤醒后便去读取共享文件的数据 读完后便去睡眠等待 

#### 线程

1. 线程称为轻型进程或者进程元  引入线程是为了减少程序在并发执行时所付出的时空开销 (进程切换是需要为旧进程保存当前操作系统环境和参数并为新的进程创建环境)
2. 引入线程后 进程作为拥有资源的基本单位 而线程将作为独立调度和分派的基本单位

#### 作业

1. 作业是一个比程序更加广泛的概念  他包含了程序和数据而且还配有一份作业说明书 系统根据这个作业说明说来对程序进行控制
2. 作业步 在系统中作业所经过的若干个独立或者关联的处理步骤称为作业步  比如编译 装配 运行等
3. JCB 作业控制块 方便系统进程管理和调度 包含了作业标示 用户名称 账户 作业类型(cup繁忙型 i/o繁忙型 调度优先级 资源需求 要求的内存大小 i/o设备和数量， 进入系统时间 处理时间 资源使用情况)

#### 作业调度(接纳调度)

作业调度就是按照一定的算法把作业从外存的后备队列上装入内存 并为他们创建进程分配资源。再插入到就绪队列中 

作业调度既要考虑用户的需求 又要考虑系统的效率

作业调度每次需要考虑的两个问题

1. 决定接纳多少个作业到内存  这取决于多道程序度 即同时允许多少个作业在内存中运行 
2. 决定接纳哪些作业 取决于调度算法
   1. 先来先服务
   2. 短作业优先
   3. 响应比

**在批处理系统中作业进入系统后总是先驻留在外存的后备队列上  等待调度进入内存  然后在分时系统中为了及时响应用户的需求 作业可以直接被送入内存中  也就没有了中间的作业调度步骤 **

#### 低级调度 (进程调度或者短程调度)

是一种基本的调度的方式 在分时 实时 多道批处理系统中都必须配备

低级调度决定处于就绪队列中的哪个进程将获得处理机

1. 进程调度时 保存处理机的现场信息如计数器寄存器中的内存并保存进进程的PCB中相应的单元
2. 根据某种算法看 选取处理机  
3. 分配处理机并改为运行状态 恢复现场



#### 进程调度的三个基本机制

1. 排队器 就绪进程按照一定的方式排成一个或者多个队列  方便调度程序寻找
2. 分派器 将调度程序选定的进程取出 切换上下文 分配处理机
3. 上下文切换机制 保存当前进程的现场 恢复下一个待处理的进程的现场 

上下文切换需要花去一些时间 大约几毫秒 这点时间可执行上千条指令

#### 进程调度方式

1. 分抢占式调度  一旦将处理机分配给进程后 就得一直让它运行下去  除非程序自己执行完毕或者发生阻塞或者因为请求i/o中断   这中实现简单 系统开销小
2. 抢占方式 根据某种规则暂停正在执行的程序 将处理机分配给下一个进程 具体的规则比如

#### 抢占规则

1. 优先权 优先权高的进程将夺得正在执行的优先权低的进程的执行
2. 短作业优先 明显处理起来需要更短的进程将获得处理机
3. 时间片原则 各进程按照一定的时间片轮流执行 时间片用完后就停止执行重新调度进程来执行 

#### 中级调度

为了提高内存利用率和系统吞吐量

将那些暂时不能运行还占着内存资源的进程 调至外存上等待  此时的进程状态称为就绪驻外存或者叫挂起状态  当进程重新具备执行条件或者内存稍有空闲时  中级调度决定哪些进程重新调入内存挂在就绪队列上 状态改为就绪状态 



**进程调度的频率最高10～100ms一次  作业调度几分钟一次  中级调度介于中间**



#### 选择调度方式和调度算法的若干准则

面向用户时： 

1. 周转时间短 作业被提交给系统开始。到作业完成
2. 响应时间快。用户键入一个请求到接受到系统的第一个响应时间
3. 优先权。

面向系统时：

1. 系统吞吐量大
2. 处理机利用率好
3. 各类资源的平衡利用



#### 调度算法

1. 先来先服务调度算法(FCFS)

   * 适用于作业调度  进程调度
   * 适合长作业或者进程 不适合短作业
   * 适合cpu繁忙性作业 不适合i/0密集型作业

2. 短作业(进程)优先算法 SJF/SPF

   * 适用作业调度 进程调度
   * 适合短作业或者进程 
   * 对长作业不利 完全未考虑作业的紧迫程度 有可能导致长作业完全不被调度
   * 理论上是短作业(短表示用户提供的估计执行时间比较短) 但用户提供的时间不一定准确 所以可能不一定真正的得到短作业优先

3. 高优先权调度算法 FPF

   * 常用于批处理系统 适用于作业和进程调度
   * 分为抢占式调度算法 非抢占式调度算法  非抢占一旦获得处理机一直执行直到完成 后者如果在获得处理机后又出现了一个优先权更高的进程 则立即退出执行将执行权交给优先权更高的进程
   * 静态优先权和动态优先权 静态优先权创建进程的时候确定的 给一个优先数 0～7 0～255  动态优先权赋予一个初始值 但随着进程的推进和等待时间会增加改变

   优先权确定的依据

   * 进程类型 系统的高于用户的
   * 进程对资源的需求 内存需求量少的执行时间少的高于多的
   * 用户要求 进程的紧迫程度 

4. 高响应比优先调度算法

   * 是一种折中算法 既能考虑短作业又能考虑到长作业 
   * 响应比 = (等待时间+要求服务时间) / 要求服务时间

5. 时间片轮转调度算法 

   主要分为早期的简单的时间片轮转法和多级反馈队列调度算法 

   * 时间片轮转法 
     1. 所有的进程按照先来先服务的原则排成一个队列 每次调度时将cpu分配给一个队首进程 并令其执行一个时间片 时间片的大小从几毫秒到几百毫秒不等 如果时间到了计时器发出中断请求 停止执行 并将进程插入到队尾 
     2. 时间片的确定关系着系统性能  不可过大或过小
   * 多级反馈队列调度算法 
     1. 公认的较好的进程调度算法 
     2. 设置多个就绪队列 并为各个队列赋予不同的优先级 第一个队列的优先级最高 第二个次之 其余各个优先级逐个降低  赋予每一个队列一定的时间片 优先级越高时间片越低  
     3. 仅当前面的队列为空时才会执行后面的优先级低的队列 如果有新的进程进入优先级高的队列 则新进程会抢占正在执行的队列中的进程的执行权 
     4. 适合： 终端性作业用户(交互性作业)   短批处理作业用户  长批处理作业用户 

#### 实时调度

实时调度必须能满足对实时任务的截止时间的要求 因此所有的任务必须提供下列条件

1. 就绪时间 成为就绪状态的起始时间
2. 开始截止时间和完成截止时间 
3. 处理时间
4. 资源要求
5. 优先级

#### 实时调度算法分类

1. 非抢占式调度算法
   * 轮转调度算法 实时任务排成一个队列 调度程序每次只从队首调取任务处理 新来的插入到队尾 
   * 优先调度算法 排成一列 优先级高的任务插入到队首
2. 抢占式调度算法 
   * 基于时钟中断的强占 优先级高的任务到达后并不会立即抢占处理机 而是等到时钟中断到来时 才会抢占处理机
   * 立即抢占。

#### 常见的实时调度算法

1. 最早截止时间优先(EDF) 截止时间越早 优先级越高
2. 最低松弛度优先(LLF) 松弛度的计算： 比如一个任务必须在400ms时完成 他自己本身执行需要的时间是150ms  所以处理机必须在250ms这个时间点之前开始执行 所以他的松弛度就是250ms 

#### 产生死锁的原因和必要条件 

原因： 

1. 竞争资源 (临时性资源和永久性资源)
2. 进程间推进顺序非法

必要条件

1. 互斥条件 进程所分配到的资源进行排他性使用  分配到的资源只能有一个进程占用 其他进程请求只能等待
2. 请求保持条件 进程已经保持了一个资源 同时又发出新的资源请求
3. 不剥夺条件 进程已经获得的资源在未使用完之前。不能被剥夺
4. 环路等待条件 发生死锁时必然存在一个进程-资源的环形链

#### 处理死锁的基本方法 

1. 预防死锁  添加限制条件 可能会导致资源的利用率和系统吞吐量低
2. 避免死锁  防止系统进入不安全状态 
3. 检测死锁 
4. 解除死锁  常用的方式就是挂起或者撤销一些进程 

#### 预防死锁

1. 摒弃请求保持条件 一次性把进程需要的所有资源全部分配给 如果其中有一个资源没法分配  那么所有的资源都不能分配 
2. 摒弃不剥夺条件  进程在请求新的资源未果后 必须释放自己保持的资源 
3. 摒弃环路等待条件  比前两种方式好

### 存储器管理

理想情况下 存储器的速度应该相当快 能跟上处理机的速度 

#### 多级存储器结构 

cup寄存器  <=   主存(高速缓存 主存 磁盘缓存)  <=  辅存(磁盘 可移动存储介质)

寄存器和主存也称为可执行存储器(使用load或者store指令进行访问) 对于他们中的信息的访问与辅存而言不同  辅存需要I/O设备来实现 涉及中断 设备驱动程序 物理设备运行等

存储管理主要针对的是可执行存储器的分配 回收 数据移动

1. 主存储器  内存或者主存 保存进程运行时的程序和数据  数十M到数十G
2. 寄存器 访问速度最快 能与cpu协调工作 存放操作数或者地址映射 长度以字为单位
3. 高速缓存 访问速度高于主存低于寄存器 将主存中经常访问的数据放在高速缓存中 减少对主存的访问 可大幅度提高程序执行速度 通常进程的程序或者数据是存放在主存上的 每当使用的时候 被临时复制到一个速度较快的告诉缓存中 当cpu再次访问的时候先检查高速缓存中有没有 有的话直接从高速缓存中取出使用 
4. 磁盘缓存 不是一种真实存在的介质 他是在主存中开辟一块空间专门用来存放磁盘中经常被访问的数据 可以理解为磁盘的告诉缓存 

#### 程序的装入和链接

为使程序能够运行 必须先为程序创建进程 而创建进程的第一件事就是将程序装入内存 

装入的过程：

1. 编译 编译程序将用户代码编译成若干个目标模块 
2. 链接 链接程序将目标模块和他们需要的库函数链接在一起形成一个装入模块
3. 装入 装入程序将装入模块装入内存

#### 程序的装入

1. 绝对装入方式  编译程序将直接产生绝对地址的目标代码 装入程序按照绝对的地址在内存中将程序和数据装入内存 绝对地址可在编译时或者汇编时或者由程序员直接指定 适合单道程序环境
2. 可重定位装入方式  多道程序环境编译程序事先肯定不知道应该将程序装入到内存的哪里 所以目标模块的地址一般都是0开始的 程序的其他地址也都是相对于这个起始地址计算的  此时装入程序会将目标模块在内存中选择合适的地方开始装入  程序的逻辑地址和物理地址通常都不同  所以在执行指令的时候都需要逻辑地址加上装入时的起始物理地址算出真正的物理地址  这种地址的变换通常是在装入是一次性完成的 所以叫静态重定位
3. 动态装入方式  可重定位允许将程序装入到内存的任务合适的地方 但是不允许装入移动程序  因为程序的移动导致在内存中的物理地址的变化 目标模块的计算好的所有地址又得重新计算 并且实际情况是程序的运行过程中经常会有位置的移动 所以动态装入方式是： 在编译阶段并不重定位地址 而是以程序的相对位置装入内存 直到程序真正运行的时候才计算程序的物理地址 这种方式需要一个重定位寄存器的支持

#### 程序的链接

编译程序将程序编译形成目标模块后 由链接程序链接形成装入模块

1. 静态链接 程序运行之前就先将目标模块和他们需要的库函数链接成一个完成的装入模块 其中设计到的是每个模块的地址的重新计算和拷贝
2. 装入时动态链接 边装入边更新 便于修改和更新 便于实现对目标模块的共享
3. 运行时动态链接 无论是静态链接或者装入时链接都是事先将可能运行的模块连接完成然后装入内存 这样可能造成浪费和低效 因为有些模块可能永远用不到不会运行  这种方式当发现一个调用模块未装入内存中时便由OS去找到该模块装入内存 

####  连续分配方式 

为一个用户程序分配一个连续的内存空间 就是内存空间的管理

1. 单一连续分配 最简单 只能用于单用户和单任务的系统 内存分为系统区和用户区。系统区共os使用  用户区共用户程序使用
2. 固定分区分配 最简单的多道程序存储管理管理方式  内存用户空间划分为若干个固定的区域 每个分区只装入一道作业 
   1. 按分区大小划分  分区大小相等或者不相等两种方式
   2. 内存分配 按分区大小排序 并为之建立一张分区使用表 
3. 动态分区分配 跟据进程的实际需要动态的分配内存空间
   1. 分区数据结构  空闲分区表和空闲分区链 
   2. 分配算法 
      * 首次适应算法 空闲分区链以地址递增的方式链接 找到一个大小合适的分区
      * 循环首次适应算法 从上次找到的空闲分区的下一个分区开始查找合适的分区分配
      * 最坏适应算法 空闲分区链按容量从大到小链接 每次从头开始查找
      * 最快适应算法 分区按照大小分类 每一类建立一个空闲分区链 从合适的类找合适的大小
4. 分区分配操作
   1. 分配内存
   2. 回收内存

#### 伙伴系统 

固定分区和动态分区都有不足之处 伙伴系统是他们的折衷方式

#### 哈希算法

空间分区还是按照分区大小分类 建立分区链表  哈希算法利用自身查找快的特点 建立哈希函数 快速查找空闲哈希不表表头

#### 动态重定位分配

当内存中找不到合适的分区分配给进程但内存剩下空闲分区总和大小满足进程需要内存空间时 需要移动现在的所有进程的位置 拼接或者紧凑出内存可用的空间大小 模块装入时也是相对位置 绝对位置在运行时计算的

#### 对换 

在多道程序环境下 在内存中的某些进程由于某些事件尚未发生而被阻塞运行 但他们却占用了大量的空间 有时候有可能在内存中的所有进程都处于阻塞状态进而导致cpu停止运行 严重浪费资源 所以对换就是为了将这些暂时不运行的进程调到外存上 腾出足够的内存空间 将已经具备运行条件的进程调入内存

如果对换是以进程为单位对换的 那么叫做整体对换 

如果是以段或者页为单位对换的 那么叫做部分对换 

#### 对换管理 

具有对换功能的os中。外存分为文件区和对换区。前者存放文件 后者存放对换出来的进程  由于对换的进程驻留只是暂时的 所以对于空间的管理和分配采用的是连续分配方式 同样的还是有空间管理表 

#### 进程的换出和换入

选择内存中阻塞状态且优先级最低的进程 启动磁盘 传送程序和数据到外存 回收内存空间

选择外存中就绪状态的且换出时间最久的进程换入内存 

#### 基本分页存储方式

连续分配内存方式会形成很多内存碎片 虽然通过紧凑可以形成可用的大空间 但是这会损耗很大开销 如果能将进程直接分散的装入到许多不链接的内存分区中就好了 这种离散的分配方式如果分配的基本单位是页则称为分页存储 如果基本单位是段 则称为分段存储 

#### 分页存储

将进程中的逻辑地址空间分成若干个大小相等的片 称为页面或者页 为每一页加以编号 第一页  同时吧内存空间分为页面相等大小的若干个存储块。称为物理块或者叶框 

页面大小不宜过大或者过小 应该是2的幂 通常为512B～8KB

#### 分段存储 

分页存储为的就是最大化内存空间的利用率  减少内存碎片  而分段存储则为了用户编程和使用上的放方便

1. 方便编程。将作业按照逻辑关系划分为若干个段 每个段有自己的名字和长度 
2. 信息共享。 在实现共享时比较方便 因为每一个段都是一个完整的逻辑  而分页中则不同 每个页是不完整的
3. 动态增长  分页中每个页框的大小都是提前定好的  不方便动态增长 但是实际上有些段在运行时是不断增长的 比如数据段等等 分段存储中这种是可以增张的 
4. 动态链接  运行前不会把目标程序段链接起来 而是运行时 先将目标程序段装入内存并启动运行 运行过程中再调用某段 



#### 段表 

分段存储也是一种离散分配 需要一张段表来记录逻辑段在内存中对应的物理段的位置 段表存储在寄存器中



#### 分页和分段的区别

1. 分页为了提高内存的利用率 页是物理单位 段时逻辑单位 是一组完整的有意义的信息 
2. 页大小固定有系统决定 段长度不固定 决定与用户编写的程序
3. 分页是地址空间是一维的 分段是二维的

#### 段页存储

分段和分页各有优点 段页存储就是利用他们的优点来存储

先将用户程序分为若干个段 再将每个段分为若干个页 然后将内存地址分为固定大小的分区 

同样的需要一张段页表来找出所访问的程序或者数据真正物理地址  段页表需要个高速缓冲寄存器来存储 

如果在缓冲中找不到 则需要三次访问内存才能拿到物理地址

#### 虚拟存储器

各种存储器管理方式都有一个特点： 即他们都要求将一个作业全部装入内存后才能运行

1. 有的作业很大 要求的内存空间超过了内存容量 不能转入内存 导致作业无法运行
2. 有大量作业要求运行 内存容量不足以容纳这些作业 只能将少数作业装入内存 其他作业在外存等待

常规存储器管理方式的特点

1. 一次性 必须将作业全部装入内存才能运行 但实际上运行过程中并非左右的作业和数据都要用到
2. 驻留性 作业装入内存后便一直驻留在内存中 直至作业运行结束 但实际上有些进程会因为I/O操作而长期等待或者有些程序模块运行完一次就不再运行了这两种情况都是一种浪费内存资源的情况

#### 局部性原理(一次性转入和驻留性真的有必要吗)

程序在执行时呈现局部性规律 即程序的执行在一较短时间内局限于某个部分 相应的他所访问的存储空间也局限于某个区域 

1. 程序执行除了少数的转移和过程调用指令外 都是顺序执行
2. 过程调用的轨迹是从一部分区域到另一个部分区域
3. 程序中循环结构 多次执行
4. 程序对数据结构的访问 局限在很小的一部分

局限性表现

1. 时间局限性 某些指令和数据在一次执行或者访问后 可能在不久之后被再次访问和执行
2. 空间局限性 程序访问了某个存储单元 在不久后其附近的存储单元也将被访问

#### 虚拟存储器的定义

基于局部性原理 程序的运行没有必要一次性全部装入内存 仅将那些当前要运行的少数段或者页面装入内存便开始运行。其余的驻留在磁盘上 程序运行时 如果他访问的段或者页已经调入内存则继续执行 如果没有 则启用os提供的请求页或者段功能 将他们调入内存执行 如果此时内存已满。无法在装入新的段或者页则还须利用段页置换功能及那个内存中暂时不用的页或者段调至磁盘上 腾出足够的空间后将将要访问段或者页面再调入内存 这样继续执行 

如是 一个大的程序执行仅需要一个小的内存空间 内存中也可同时装入更多的进程使他们并发执行 用户角度看系统的内存容量要比实际内存容量大的多 但这种大只是一种虚拟的感觉 所以这样的存储器叫做虚拟存储器

所谓虚拟存储器就是： 具有请求调入和置换功能 从逻辑上对内存容量加以扩充的一种存储器技术 其逻辑容量相当于内存容量和外存容量之和决定 

#### 虚拟存储器的实现

1. 采用离散式的内存分配策略 
2. 分页或分段请求系统 
   1. 硬件支持
      * 请求分页或者分段的页表机制 
      * 缺页或缺段中断机构 用户要访问的页面或段不在内存中时 产生中断。以请求os需要的页或者段
      * 地址变换机构 



#### 虚拟存储器的特征

1. 多次性。一个作业会被分成多次调人内存 
2. 对换性  允许在运行过程中对那些暂时不用的数据或者程序调入外存 将需要的调入内存
3. 虚拟性。在逻辑上扩充内存容量  用户看到的内存容量要大于实际内存容量



#### 请求分页存储管理方式

请求分页为了能支持虚拟存储功能增加了请求调页功能和页面置换功能 同时每次调入和置换的都是长度固定的页面。这使得请求分页比请求分段系统简单 所以请求分页是比较便成为了目前最常用的实现虚拟存储的技术 

#### 请求分页的硬件支持

1. 一定容量的内存和外存的计算机系统
2. 页表机制 记录页面的信息 方便逻辑地址和物理地址的转换 页号。状态位 表示该页是否已经调入内存 访问字段A 表示该页在一段时间内被访问的次数或者多长时间未被访问 供页面置换时参考  修改位M。表示该页在被调入内存后时候被修改过。这是因为外存上同时保存着该页的一份副本 如果在页面置换时该页已经被修改过 则必须将页面重新写到外村上 保持外村的页面最新  外存地址 通过指的是外存的物理块号 供调入该页时参考 
3. 缺页中断机构 每当所访问的页面不在内存中时。变产生一次中断 请求os将所缺的页面调入内存 缺页中断是一次中断  所以他需要在中断时保护cpu环境 分析中断原因 转入缺页程序 恢复cpu环境等。它与一般的中断的区别是： 
   1. 在指令执行期间产生和处理中断信号 通常都是cpu都是在一条指令执行完毕后才检查是否有中断请求到达 
   2. 一条指令执行期间。可能多次产生缺页中断 
4. 地址变换机构 

#### 内存分配策略和分配算法

在为进程分配内存时 设计三个问题 最小物理块数的确定  物理块的分配策略 物理块的分配算法 

1. 最小物理块数的确定。能保证进程正常运行的最小物理块数。少于此值无法运行   最小物理块数的与计算机的硬件机构有关系 取决于指令的格式 功能和寻址方式
2. 物理块的分配策略 内存分配采用固定和可变分配 置换采用全局置换和布局置换。综上有三种组合策略
   1. 固定分配局部置换 为每个进程分配一定数目的物理块 整个运行期间都不变 如果发生缺页中断 则从分配的n个物理块中选出一个置换 这个分配策略的难点在于如何确定进程的物理块数 太多容易浪费 太少出现频繁缺页中断 
   2. 可变分配局部置换 为进程先分配一定数目的物理块 同时os维护一个空闲物理块队列 当某个进程发生缺页时便从空间队列取出一个物理块分配给这个进程 当空间队列分配完了的时候 才会从系统的人一个一个进程中选择一页进行置换  最容易实现和最常用的
   3. 可变分配局部置换   同样的为每个进程分配一定数目的物理块 如果进程频繁的发生中断 则为这个进程再分配一定的物理块  如果这个进程在运行过程中缺页率特别低 则可适当减少分配给该进程的物理块 



#### 物理块的分配算法

1. 平均分配算法 100个物理块 20个进程。每个进程5个物理块  实际上不公平
2. 按比例分配 按进程的大小比例分配 
3. 按优先权分配 重要的紧迫的作业尽快的完成。分配多的内存空间 

#### 调页策略 

1. 预调页策略 一次调入相领的页 
2. 请求调页策略 

#### 页面置换算法

程序运行过程中需要将不在内存中的页面调入内存 但是内存已经满了 此时需要将内存中某一页面调出到外存的对换区。调哪个页面就是页面置换算法 

理论上说选择那些以后不会使用或者未来很长时间不会使用的页面置换出去最好 这样具有最低的置换频率

1. 最佳置换算法 是一种理想的理论算法 很难实现 
2. 先进先出置换算法   最简单 效率低 
3. 最近最久未使用置换算法 想前看的算法 需要硬件支持 寄存器和栈
4. Clock算法 最近未用算法 
5. 最少使用算法 
6. 页面缓冲算法 

#### 设备管理

就是实现输入和输出和数据存储的系统

#### I/O设备类型

1. 按照使用特性分
   1. 存储设备 外村或者后备存储器
   2. 输入输出设备 交互式设备  鼠标 键盘 扫描仪 

2. 按传输速率
   1. 低速 每秒几个或者几百个字节 键盘 鼠标等
   2. 中速 每秒几千个或者数万个字节 行式打印机激光打印机
   3. 高速 每秒数百个千字节或者兆字节 磁带机 磁盘机 光盘机 
3. 按消息交换分类 
   1. 块设备 存储数据的 有结构设备 速率高 可寻址  典型的磁盘 每个盘块的大小是512B～4KB 
   2. 字符设备 输入输出的 无结构 不可寻址

4. 按共享属性分
   1. 独占设备 临街资源  可造成死锁 
   2. 共享设备 可寻址 可随机访问  例子是磁盘 
   3. 虚拟设备 通过虚拟技术将物理设备变成若干逻辑设备

#### 设备与控制器之间的接口

设备不与cpu直接通信 而是与设备控制器通信 因此设备中应该有设备与控制器之间的接口。接口信号线： 

1. 数据线。数据线经过缓冲器在经过转换器输入输出
2. 控制线  用来从设备控制器想设备发送控制信号的通路 包括读写操作 移动磁头等操作
3. 状态线。用来传输当前设备的状态的线路 正在读还是正在写 

#### 设备控制器

是实体。用来控制一个或者多个设备 它是cpu和设备之间接口。接受cpu的命令来控制设备 在cpu和设备之间传递数据  设备控制器可编址

#### 类型

1. 控制字符设备控制器 
2. 控制块设备控制器 

在微型机中 设备控制器被做成一个印刷电路卡形式 称为接口卡 可插入计算机 

#### 设备控制器的基本功能 

1. 接收和识别命令 接收设备控制器的命令Read Write Format等
2. 数据交换

3. 标示和报告设备的状态 
4. 地址识别
5. 数据缓冲 
6. 差错控制 

#### 设备控制器的组成 

1. 设备控制器与处理机之前的接口
2. 控制器与设备的接口
3. I/o设备逻辑

#### I/O通道

虽然cpu与i/o设备之间已经增加了设备控制器 但是当主机配置的外设很多时。cpu的负担仍然很重 为此 在cpu和设备管理器之间又增加了通道  增加通道的目的是为了分担cpu的压力 把cpu从繁杂的i/o任务中解脱出来 将有关io的一些操作尽量独立出来 

有了io通道 cpu只需向通道发送一条io指令 通道在接受到该指令后便从内存中取出本次要执行的通道程序 然后执行该通道程序 尽当通道完成规定了io任务后 才向cpu发出中断信号

通道实际上就是一种特殊的处理机  它具有执行io指令的能力 但是它也有区别： 

1. 指令类型单一 只能执行简的io操作指令
2. 没有自己的内存 和处理机共享主存

#### 通道的类型

1. 字节多路通道 一个主通道 多个子通道 每个字通道连接一个io设备 控制一个设备的io操作 每个子通道按照时间片轮转的方式共享主通道 适合在设备速率不是太高的情况 不适合链接高速设备
2. 数组选择通道 可以链接高速设备 但是只有一个子通道 只能连接一个设备 利用率低
3. 数组多路通道  上述两种通道的结合

通道的价格很贵 导致机器中配置的通道数量不会很多 这就造成了io的性能瓶颈 

解决的方式是： 不增加通道数量 但是增加设备到内存或者处理机之间的链接的通路的数量 

#### 总线系统

cpu 内存 各种io设备之间的联系就是通过总线实现 总线的性能衡量指标就是：时钟频率 带宽 传输速率 

随着计算机cpu 内存的速率的发展 字长的增加 对总线的也提出了要求 总线的发展 

1. ISA。1984年 带宽8位。速率2Mb/s。连12台设备 
2. EISA。20世纪80年代末期  带宽32位 32Mb/s. 连12台设备 
3. VESA。1990年。 低价位 带宽32位。速率 132Mb/s 链接2～4台设备 
4. PCI  速率132Mb/s   10台设备

#### I/O控制方式 

i/o控制方式的发展就一个宗旨。尽量减少主机对I/O控制的干预 

1. 程序io方式  忙等待方式 处理机向io控制器发出一条指令 同时将状态寄存器标志改为1。然后便不断的循环轮询寄存器 直到标志为0时说明数据已经输入到数据寄存器中。处理机便开始读输入并写到内存中 然后重复再。 由于cpu的高速性和io的低速性。导致cpu一直在不断的测试io控制器中状态寄存器的状态 造成极大资源浪费
2. 中断驱动io控制方式  现在的计算机中都引入了中断机构 cpu向控制器发出指令后 立即返回继续执行原来的任务 cpu和io设备并行操作等到io操作完成后  设备控制器发出一个中断请求 cpu便停下手中的活检查操作的正确性并写入数据到内存
3. 直接存储器访问控制方式 DMA 中断驱动虽然很有效 但是他是以字为单位的进行的  没完成一个字或者字节的io时 变发生一次中断 如果对一个块磁盘的io操作 这是低效的。因为需要进行大量的中断。读1KB数据 中断cpu一千次 随意引入了直接访问存储器方式 
   1. 传输单位是数据块 例如一个盘块的大小是512B～4KB 
   2. 传输的数据从设备直接送入内存
   3. 仅在完成一个或多个数据块的情况 才会有cpu的干预  整块数据的传输从控制器的控制下完成的 
4. io通道方式 可以一次读取一组数据块的访问 

#### 缓冲管理

引入缓冲的原因： 

1. 缓和cpu与io设备速度不匹配的矛盾 事实上  凡是数据到达速率和离开速率不匹配的地方都应设置缓冲区
2. 减少cpu的中断频率 不然必须每到达一位数据就中断一次cpu
3. 提高cpu和io设备之间的并行性 

缓冲类型： 

1. 单缓冲 用户进程发起io请求 os在内存中为之分配一块缓冲区 

2. 双缓冲 为了加快输入输出速率 第一缓冲区输入完成后可以转到第二缓冲区 生产和消费的速度相当时 可以达到并行的效果 

3. 循环缓冲  上面输入和输出速率相当时可以理想的并行执行输入和输出进程 但是如果不匹配就行了 这时引入了多个缓冲区  情况有所改善 

   循环缓冲的组成： 

   1. 多个缓冲区 大小相同 分为已经装满数据的 空闲的 计算进程正在操作的 
   2. 多个指针。计算进程下一个可以用的缓冲区Nextg 输入进程下次可用的Nexti  计算进程正在操作的current

   循环缓冲的使用： 类似操作环形链 

   1. Getbuf过程 计算进程获取缓冲区数据的过程 此时牵扯到指针的变换 current变为Nextg  Nextg指向下一个缓冲区
   2. Releasebuf过程 计算进程取完缓冲区的数据时。释放当前缓冲区 

   进程同步的问题： 计算进程和输入进程可以并行的执行 但是有两种特殊情况 

   1. Nexti追赶上Nextg。意味着输入进程速度大于计算进程速度 循环缓冲链满了 
   2. Nextg追赶上Nexti  意味着计算进程速度大于输入进程。缓冲区空了 

4. 缓冲池 上面的缓冲区仅适用于特定的进程和计算进程。系统较大时 如果有很多这样的缓冲区浪费资源 目前共用的是公用缓冲池 在池中建立多个可供若干个进程共享的缓冲区

   缓冲池组成： 

   1. 空闲
   2. 装满输入数据的
   3. 装满输出数据的

   每一种类型的缓冲区链接组成同种类型的队列 记住：这三种队列都是临界资源 需要进程互斥的访问

   缓冲池的操作： 

   1. 收容输入时：输入进程从空闲队列队首取下一个空闲缓冲区 然后输入数据 最后挂在输入队列上。
   2. 收容输出时：输出进程从空闲队列上取下一个空闲区 输出数据 挂在输出队列上 
   3. 提取输入时： 从输入队列上取下一个缓冲区 提取数据 取完后将空闲缓冲区挂在空闲队列上 
   4. 提取输出时： 从输出队列上取下一个缓冲区 取完数据 将空闲缓冲区挂在空闲队列上

#### io软件

计算机系统中的io设备种类很多 硬件设计复杂 如果让用户直接操作很困难 io软件用来屏蔽这些差异 提供用户方便简单的接口来操作这些设备 因此io软件的目标就是： 

1. 与具体设备无关
2. 统一命令 给物理设备给一个逻辑名称
3. 错误处理 
4. 缓冲处理
5. 设备的分配和释放
6. 选择合理的io控制方式

通常将io软件分为几个层次： 

1. 用户层软件。与用户直接交互 用户可以直接调用软件提供的接口操作io设备 
2. 设备独立软件 实现与设备驱动器的统一接口 设备命名 设备保护 设备的分配和释放 
3. 设备驱动程序  与硬件直接相关 负责实现系统对设备的操作命令 
4. 中断处理程序 保存被中断的cpu环境 转入到相应的中断处理程序处理 恢复现场 

中断处理程序的工作： 用户进程请求io操作时 进程将被挂起 直到io设备完成操作后 设备控制器发出中断请求 cpu转向中断处理程序处理 

1. 唤醒被阻塞的设备驱动程序
2. 保护被中断的cpu环境 
3. 转入到相应的设备处理程序
4. 中断处理 判断中断的状态 
5. 恢复中断的进程的现场

#### 设备驱动程序 

又称为设备处理程序 专门用来在io进程和设备控制器之间的通信 通常以进程的形式存在 接受上层软件的抽象io命令 如write等 转为具体的要求后发送给设备控制器 

设备驱动程序的功能： 

1. 接受设备独立软件来的命令 
2. 检查用户io请求的合法性
3. 发出io命令
4. 构成通道程序

#### 设备独立软件

设备驱动程序是一个和硬件之间相关的软件 为了实现设备独立性 必须在驱动程序之上再加一层软件 就是设备独立软件 有些设备独立软件设计在驱动程序中  根据操作不一样 

功能主要有： 

1. 执行共有的操作
2. 向用户层提供接口 

物理设备名和逻辑设备名之间的映射的实现

1. 逻辑设备表(LUT) 逻辑设备名 物理设备名 驱动程序入口地址

#### 用户层的io软件

大部分的io软件都在操作系统内部 仍有一小部分在用户层 包括与用户程序连接在一起的库函数

#### 设备分配

用户进程请求设备时 在确保安全的前提下 将设备分配给用户进程 有的系统还要同时将设备控制器和设备通道也分配给用户进程才算此次设备分配完成。

设备分配时需要借助一些数据结构表 

1. 设备控制表 包括了设备类型type 设备ID 设备队列队首指针(凡是请求设备没有得到资源的进程 其进程PCB都会在按照一定的策略排成一个队列 方便后面继续分配) 设备状态(忙还是闲) 与设备连接的控制器表指针 重复执行次数(一般外部设备在传送数据时都会发生错误 但这并不会立即被认为是失败 而是继续重新传送 这个字段规定了允许的重新传送的次数)
2. 控制器控制表 
3. 通道控制表
4. 系统设备表

设备分配时考虑的因素

1. 设备固有属性 独占 共享 还是可虚拟
2. 设备分配算法 先来先服务 高优先级
3. 设备分配的安全性 安全性 不安全性 防止进入死锁

独占设备的分配过程

1. 根据IO请求中的设备物理名称 在系统设备表(SDT)中查找这个设备的设备控制表(DCT)  根据DCT中的设备状态字段判断设备是否忙 忙则将用户进程的PCB挂在设备队列上 闲则计算分配设备的安全性 不会导致进入不安全状态就会分配 会则将PCB插入到设备等待队列
2. 分配完设备后  再从DCT中找到与设备连接的控制器的COCT 从COCT中的状态字段中判断设备控制器忙不忙  不忙则分配控制器给用户进程 忙就用用户进程PCB挂在等待队列上
3. 分配通道 从COCT表中可以找到与设备控制器连接的通道的CHCT 同理 根就他的状态字段判断忙不忙 不忙就分配通道给进程 忙就将PCB插入到等待队列上 至此 设备 设备控制器  设备通道都分配完成就能算一次设备分配成功

设备分配的改进

上面所说的分配策略有一定的瓶颈。增加设备的独立性 和考虑多通路情况会有所改善 设备独立性 就是用户进程改用逻辑名称请求设备分配 这样系统就会在SDT中挨个找该类设备的DCT 第一个忙就会找第二个等等 

考虑多通路情况 现在的系统都是采用的多通路的IO系统结构 如果设备控制器连接的第一个设备通道忙。就会挨个找第二个控制器通道  



#### SPOOLing技术 

脱机输入和脱机输出技术 就是将一台物理设备虚拟成多台逻辑设备 为了就是缓和cpu的高速性和设备的低速性 利用专门的外围控制机将低速IO设备上的数据传送到高速磁盘傻姑娘 或者相反

组成 

1. 输入井和输出井 在磁盘上开辟的两大存储空间 用户暂存IO设备的输入数据 和  用户进程的输出数据
2. 输入缓冲区和输出缓冲区 在内存中开辟的两个缓冲区 缓和cpu和磁盘的速度不匹配  输入缓冲区用来暂存有输入设备送来的数据 以后再传送到输入井 输出缓冲区用来暂存输出井送来的数据 以后再传送到输出设备上 
3. 输入进程SPi和输出进程SPo。输入进程模拟脱机输入的外围控制机 将用户要求的数据从输入机通过输入缓冲区再传送到输入井中 当cpu需要这个数据时候直接输入井读入内存 输出进程用来将用户要求输出的书就先冲内存中传送到输出井中 在输出设备空闲时再从输出井中将数据传送到内存中的输出缓冲区中 最后输出到输出到设备上 

SPOOLing技术的特点

1. 提高io速度
2. 独占设备变为共享设备。共享打印机用了该技术
3. 实现了虚拟设备